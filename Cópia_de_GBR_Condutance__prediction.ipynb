{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**"
      ],
      "metadata": {
        "id": "OD10INsf657y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script provides an automated pipeline for predicting conductance in twisted bilayer graphene systems using machine learning. The process integrates data normalization, clustering with a Self-Organizing Map (SOM), and regression with Gradient Boosting Regressors (GBR).\n",
        "\n",
        "The workflow ensures that any new input follows the same transformation pipeline as the training data, maintaining consistency in predictions. The key steps include downloading pre-trained models and scalers, clustering new input data based on learned patterns, selecting the appropriate GBR model for the identified cluster, and producing a final conductance prediction.\n",
        "\n",
        "By structuring the workflow in an automated and modular way, this approach significantly reduces computational costs compared to traditional simulations while preserving accuracy in conductance predictions."
      ],
      "metadata": {
        "id": "6lvw1_Fl5DO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Guide: Running the Conductance Prediction Pipeline"
      ],
      "metadata": {
        "id": "C2ZmhmNR-fz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå User Guide: Running the Conductance Prediction Pipeline\n",
        "\n",
        "This user guide provides a step-by-step explanation of how to execute the conductance prediction pipeline in this Colab notebook. The notebook is structured into multiple sections, ensuring a seamless process from dependency installation to final predictions.\n",
        "\n",
        "## 1.  Installing Required Dependencies\n",
        "\n",
        "*   Before running the main code, all necessary Python libraries must be installed. This is done in Section 1, where essential packages such as MiniSom, numpy, scikit-learn, and pandas are installed.\n",
        "*   Ensure that all required packages are installed before running the pipeline.\n",
        "\n",
        "\n",
        "## 2. Downloading and Loading Pre-Trained Models\n",
        "\n",
        "\n",
        "*   In Section 2, the script downloads pre-trained models and scalers required for predictions. It verifies that all files are correctly retrieved before proceeding.\n",
        "*   The script checks whether each file is present and successfully loaded.\n",
        "If any file is missing or fails to load, an error message is displayed for debugging.\n",
        "\n",
        "## 3. Loading and Initializing the Models\n",
        "\n",
        "*   This step ensures that all necessary components are in memory before making predictions.\n",
        "\n",
        "## 4. Making Predictions with a New Input\n",
        "\n",
        "*   In section 4, users can input a new angle configuration to predict conductance. To perform a prediction, type the angle values in the variable.\n",
        "\n",
        "* The energy (ùê∏) will be in the range of 0.285 to 0.306. Values ‚Äã‚Äãoutside this range can lead to unreliable predictions as the model has not been trained beyond these limits.\n",
        "\n",
        "*   Angle (ùúÉ) (twist angle between graphene layers), must be within the range 1.17¬∞ to 4¬∞. Any value outside this range produce inaccurate results.  Values ‚Äã‚Äãoutside this range can lead to unreliable predictions as the model has not been trained beyond these limits.\n",
        "\n",
        "*   Arrival and Exit Pairs were indexed according to the following mapping:\n",
        "\n",
        "\n",
        "*   The \"u\" (up) and \"d\" (down) indicate the layer of the bilayer graphene where the contact is located.\n",
        "![TBG Device](https://drive.google.com/uc?export=view&id=1mg4eskPu94C0zm0Dwt5EioFTZxFmLDpX)\n"
      ],
      "metadata": {
        "id": "6K4y5E33-Lkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running the code**\n"
      ],
      "metadata": {
        "id": "B6i-g3b0j3mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Press the \"Play\" button in every code cell\n",
        "*   In section 3, user have to type the choosen angle to predict after running the cell. ( It shows up bellow the code cell)"
      ],
      "metadata": {
        "id": "nuZnoYHRkbTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 1: Environment Setup and Package Installation**\n",
        "\n",
        "*  If an error message shows up during the installation process, you can safely ignore it. The warning is caused by version conflicts with other packages that are not required for this program.\n",
        "\n",
        "*   Ignore the red \"run\" button after running the code cell.\n",
        "\n",
        "*  Wait for the message \"‚úÖ Environment setup complete. Ready to proceed!\" to run other cell code."
      ],
      "metadata": {
        "id": "QQbOrsPI7OsQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u8_ALmFwoj0_",
        "outputId": "a50825a8-dd63-4ea1-96ec-67bc5fecd90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment setup complete. Ready to proceed!\n"
          ]
        }
      ],
      "source": [
        "# 1Ô∏è‚É£ Desinstalar TODOS os pacotes\n",
        "!pip freeze | xargs pip uninstall -y 2>/dev/null\n",
        "\n",
        "# 2Ô∏è‚É£ Instalar apenas os pacotes necess√°rios\n",
        "!pip install numpy==2.0.0 joblib==1.4.2 scikit-learn==1.6.0 minisom==2.3.3 gdown pandas --no-warn-script-location > /dev/null 2>&1\n",
        "\n",
        "# 3Ô∏è‚É£ Exibir mensagem de conclus√£o\n",
        "print(\"‚úÖ Environment setup complete. Ready to proceed!\")\n",
        "\n",
        "import time\n",
        "time.sleep(2)\n",
        "\n",
        "# 3Ô∏è‚É£ Reiniciar o ambiente para garantir que tudo funcione corretamente\n",
        "import os\n",
        "os._exit(00)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Downloading and Verifying the Required Files"
      ],
      "metadata": {
        "id": "ZE83VPTg2nUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Downloading and Verifying the Required Files\n",
        "*  Wait for the print message \"‚úÖ Environment setup complete. Ready to proceed!\" to run the cell code bellow\n",
        "\n",
        "*   Retrieves pre-trained models, scalers, and the trained SOM from Google Drive.\n",
        "*   Ensures all required files are downloaded and successfully loaded."
      ],
      "metadata": {
        "id": "d2Woj7SE_OH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from minisom import MiniSom\n",
        "\n",
        "\n",
        "# List of required files from Google Drive (direct download links)\n",
        "files = {\n",
        "    \"minisom_clusterizer.pkl\": \"https://drive.google.com/uc?id=1Go6sv941JqSWCQG5ph50shK_kiGRFdHj\",\n",
        "    \"scaler_X_standard.pkl\": \"https://drive.google.com/uc?id=1J1oTumvZBXhSdpw6HtCU7OFLqedOyQrI\",\n",
        "    \"scaler_X_minmax.pkl\": \"https://drive.google.com/uc?id=1Pbx5Ra858LvD7Crj_snJfJTMPfhsK37Y\",\n",
        "    \"scaler_y_standard.pkl\": \"https://drive.google.com/uc?id=1JxghZVBzDyB0pIED4SW0MhpdgtTq5kBI\",\n",
        "    \"scaler_y_minmax.pkl\": \"https://drive.google.com/uc?id=1Iw_VO4a1nqPaEiBCV-UsuwtM10VhWisc\",\n",
        "\n",
        "    # GBR Models for each cluster\n",
        "    \"gbr_model_cluster_0.pkl\": \"https://drive.google.com/uc?id=1Jf2y8mph0GKJJe6OxvDUlbyFJvVQvEKF\",\n",
        "    \"gbr_model_cluster_1.pkl\": \"https://drive.google.com/uc?id=1nu4DcI73dSbGH32-6_1XZv1Kki8R7ooP\",\n",
        "    \"gbr_model_cluster_2.pkl\": \"https://drive.google.com/uc?id=1c3owJkSuKrVPl1TeyA0G4E5rWbxGVkMA\",\n",
        "    \"gbr_model_cluster_3.pkl\": \"https://drive.google.com/uc?id=1cRE_A06sjSyU7Ftluz7Wzmx_w6QrKNNN\",\n",
        "    \"gbr_model_cluster_4.pkl\": \"https://drive.google.com/uc?id=1qFHJQI85s32WA-vS3lPwtKytJlsHr1eS\",\n",
        "    \"gbr_model_cluster_5.pkl\": \"https://drive.google.com/uc?id=1Zp70J-eATA0c50pBkVKOfjqC_xolOkAU\",\n",
        "    \"gbr_model_cluster_6.pkl\": \"https://drive.google.com/uc?id=19V2RD_dQhCWlpICm647HRoREZ3b9Ni9C\",\n",
        "    \"gbr_model_cluster_7.pkl\": \"https://drive.google.com/uc?id=1H-1DDKV5cdDAQc69gtDh1McSnsNY9Siq\",\n",
        "    \"gbr_model_cluster_8.pkl\": \"https://drive.google.com/uc?id=1AKXrzH3Q8kSxMp6l15zJfLaAxA_6zkkv\",\n",
        "}\n",
        "\n",
        "# Download all required files from Google Drive\n",
        "for filename, url in files.items():\n",
        "    gdown.download(url, filename, quiet=False)\n",
        "\n",
        "print(\"‚úÖ All files have been successfully downloaded!\")\n",
        "\n",
        "# List all downloaded files in the current directory\n",
        "downloaded_files = os.listdir()\n",
        "print(\"üìÇ Downloaded files:\")\n",
        "print(downloaded_files)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Function to verify file loading\n",
        "def verify_file_loading(file_name, variable_name):\n",
        "    if file_name in downloaded_files:\n",
        "        try:\n",
        "            obj = joblib.load(file_name)\n",
        "            print(f\"‚úÖ {file_name} successfully loaded into variable {variable_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading {file_name}: {e}\")\n",
        "    else:\n",
        "        print(f\"‚ùå File {file_name} NOT found!\")\n",
        "\n",
        "# Verify MiniSom\n",
        "verify_file_loading(\"minisom_clusterizer.pkl\", \"som\")\n",
        "\n",
        "# Verify Normalizers\n",
        "verify_file_loading(\"scaler_X_standard.pkl\", \"scaler_X_standard\")\n",
        "verify_file_loading(\"scaler_X_minmax.pkl\", \"scaler_X_minmax\")\n",
        "verify_file_loading(\"scaler_y_standard.pkl\", \"scaler_y_standard\")\n",
        "verify_file_loading(\"scaler_y_minmax.pkl\", \"scaler_y_minmax\")\n",
        "\n",
        "# Verify GBR Models\n",
        "for i in range(9):\n",
        "    verify_file_loading(f\"gbr_model_cluster_{i}.pkl\", f\"gbr_model_cluster_{i}\")\n",
        "\n",
        "print(\"\\n‚úÖ Verification completed! If any errors occur, check the Google Drive file IDs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO_PcQqVYB7e",
        "outputId": "8fbfe7f9-4d5f-4401-ed4b-7c615265ac5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Go6sv941JqSWCQG5ph50shK_kiGRFdHj\n",
            "To: /content/minisom_clusterizer.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.05k/7.05k [00:00<00:00, 8.22MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1J1oTumvZBXhSdpw6HtCU7OFLqedOyQrI\n",
            "To: /content/scaler_X_standard.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.06k/1.06k [00:00<00:00, 2.24MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Pbx5Ra858LvD7Crj_snJfJTMPfhsK37Y\n",
            "To: /content/scaler_X_minmax.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 823/823 [00:00<00:00, 2.33MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JxghZVBzDyB0pIED4SW0MhpdgtTq5kBI\n",
            "To: /content/scaler_y_standard.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 623/623 [00:00<00:00, 1.87MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Iw_VO4a1nqPaEiBCV-UsuwtM10VhWisc\n",
            "To: /content/scaler_y_minmax.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 719/719 [00:00<00:00, 1.51MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Jf2y8mph0GKJJe6OxvDUlbyFJvVQvEKF\n",
            "To: /content/gbr_model_cluster_0.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.4M/44.4M [00:00<00:00, 56.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nu4DcI73dSbGH32-6_1XZv1Kki8R7ooP\n",
            "To: /content/gbr_model_cluster_1.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.07M/9.07M [00:00<00:00, 16.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c3owJkSuKrVPl1TeyA0G4E5rWbxGVkMA\n",
            "To: /content/gbr_model_cluster_2.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.1M/74.1M [00:01<00:00, 42.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cRE_A06sjSyU7Ftluz7Wzmx_w6QrKNNN\n",
            "To: /content/gbr_model_cluster_3.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62.3M/62.3M [00:01<00:00, 55.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qFHJQI85s32WA-vS3lPwtKytJlsHr1eS\n",
            "To: /content/gbr_model_cluster_4.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.9M/55.9M [00:02<00:00, 22.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zp70J-eATA0c50pBkVKOfjqC_xolOkAU\n",
            "To: /content/gbr_model_cluster_5.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53.7M/53.7M [00:01<00:00, 45.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19V2RD_dQhCWlpICm647HRoREZ3b9Ni9C\n",
            "To: /content/gbr_model_cluster_6.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.0M/37.0M [00:00<00:00, 39.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1H-1DDKV5cdDAQc69gtDh1McSnsNY9Siq\n",
            "To: /content/gbr_model_cluster_7.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75.6M/75.6M [00:01<00:00, 47.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AKXrzH3Q8kSxMp6l15zJfLaAxA_6zkkv\n",
            "To: /content/gbr_model_cluster_8.pkl\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59.2M/59.2M [00:01<00:00, 30.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All files have been successfully downloaded!\n",
            "üìÇ Downloaded files:\n",
            "['.config', 'gbr_model_cluster_6.pkl', 'gbr_model_cluster_7.pkl', 'gbr_model_cluster_8.pkl', 'gbr_model_cluster_3.pkl', 'scaler_y_standard.pkl', 'scaler_y_minmax.pkl', 'gbr_model_cluster_5.pkl', 'scaler_X_minmax.pkl', 'scaler_X_standard.pkl', 'gbr_model_cluster_1.pkl', 'minisom_clusterizer.pkl', 'gbr_model_cluster_2.pkl', 'gbr_model_cluster_4.pkl', 'gbr_model_cluster_0.pkl', 'sample_data']\n",
            "\n",
            "\n",
            "‚úÖ minisom_clusterizer.pkl successfully loaded into variable som\n",
            "‚úÖ scaler_X_standard.pkl successfully loaded into variable scaler_X_standard\n",
            "‚úÖ scaler_X_minmax.pkl successfully loaded into variable scaler_X_minmax\n",
            "‚úÖ scaler_y_standard.pkl successfully loaded into variable scaler_y_standard\n",
            "‚úÖ scaler_y_minmax.pkl successfully loaded into variable scaler_y_minmax\n",
            "‚úÖ gbr_model_cluster_0.pkl successfully loaded into variable gbr_model_cluster_0\n",
            "‚úÖ gbr_model_cluster_1.pkl successfully loaded into variable gbr_model_cluster_1\n",
            "‚úÖ gbr_model_cluster_2.pkl successfully loaded into variable gbr_model_cluster_2\n",
            "‚úÖ gbr_model_cluster_3.pkl successfully loaded into variable gbr_model_cluster_3\n",
            "‚úÖ gbr_model_cluster_4.pkl successfully loaded into variable gbr_model_cluster_4\n",
            "‚úÖ gbr_model_cluster_5.pkl successfully loaded into variable gbr_model_cluster_5\n",
            "‚úÖ gbr_model_cluster_6.pkl successfully loaded into variable gbr_model_cluster_6\n",
            "‚úÖ gbr_model_cluster_7.pkl successfully loaded into variable gbr_model_cluster_7\n",
            "‚úÖ gbr_model_cluster_8.pkl successfully loaded into variable gbr_model_cluster_8\n",
            "\n",
            "‚úÖ Verification completed! If any errors occur, check the Google Drive file IDs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Loading Models and making Predictions"
      ],
      "metadata": {
        "id": "BXjfxIsd3gR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Models and Performing Predictions\n",
        "\n",
        "*   Loads the trained MiniSOM, scalers, and GBR models for each cluster.\n",
        "\n",
        "\n",
        "### Making a prediction\n",
        "\n",
        "*   Normalize the input data (energy, angle, contact pairs) using the pre-trained scalers.\n",
        "\n",
        "*   Identifies the corresponding cluster using the trained SOM and selects the appropriate GBR model for prediction.\n",
        "\n",
        "*   Predict the conductance using the chosen GBR model.\n",
        "\n",
        "*   Denormalize the predicted conductance to return a final real-world value.\n",
        "\n",
        "\n",
        "### *** After running the code cell type the angle configuration bellow the code cell.***"
      ],
      "metadata": {
        "id": "5WUfw5WA_kx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# üìå Carregar MiniSom treinado\n",
        "som = joblib.load(\"minisom_clusterizer.pkl\")\n",
        "\n",
        "# üìå Obter dimens√µes do SOM\n",
        "som_x, som_y = som._weights.shape[:2]\n",
        "\n",
        "# üìå Carregar escaladores\n",
        "scaler_X_standard = joblib.load(\"scaler_X_standard.pkl\")\n",
        "scaler_X_minmax = joblib.load(\"scaler_X_minmax.pkl\")\n",
        "scaler_y_standard = joblib.load(\"scaler_y_standard.pkl\")\n",
        "scaler_y_minmax = joblib.load(\"scaler_y_minmax.pkl\")\n",
        "\n",
        "# üìå Carregar modelos GBR para cada cluster\n",
        "models = {i: joblib.load(f\"gbr_model_cluster_{i}.pkl\") for i in range(9)}\n",
        "\n",
        "print(\"‚úÖ Modelos e escaladores carregados!\")\n",
        "\n",
        "# üìå Fun√ß√£o para gerar todos os pares de contato v√°lidos\n",
        "def generate_contact_pairs():\n",
        "    return [(i, j) for i in range(1, 9) for j in range(1, 9) if i != j]\n",
        "\n",
        "# üìå Fun√ß√£o para prever condut√¢ncia para um √¢ngulo espec√≠fico\n",
        "def predict_conductance_for_angle(angle):\n",
        "    print(\"üîÑ Gerando pares de contato...\")\n",
        "\n",
        "    # üìå Gerar todas as combina√ß√µes de ArrivalPair e ExitPair\n",
        "    contact_pairs = generate_contact_pairs()\n",
        "\n",
        "    # üìå Criar DataFrame com todas as combina√ß√µes poss√≠veis\n",
        "    data = []\n",
        "    for arrival, exit_ in contact_pairs:\n",
        "        # üìå Criar 206 valores de energia no intervalo [0.285, 0.306]\n",
        "        energy_values = np.linspace(0.285, 0.306, 206)\n",
        "        for energy in energy_values:\n",
        "            data.append([energy, angle, arrival, exit_])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Energy\", \"Angle\", \"ArrivalPair\", \"ExitPair\"])\n",
        "\n",
        "    print(f\"\\n‚úÖ DataFrame criado com {len(df)} amostras!\")  # Deve conter 9476 amostras\n",
        "\n",
        "    # üìå Exibir 5 amostras antes da normaliza√ß√£o\n",
        "    print(\"\\nüìå 5 Random Samples Before Normalization:\")\n",
        "    print(df.sample(n=5, random_state=42))\n",
        "\n",
        "    # üìå Normalizar os dados\n",
        "    df_standardized = scaler_X_standard.transform(df)\n",
        "    df_normalized = scaler_X_minmax.transform(df_standardized)\n",
        "\n",
        "    df_normalized_df = pd.DataFrame(df_normalized, columns=[\"Energy\", \"Angle\", \"ArrivalPair\", \"ExitPair\"])\n",
        "    print(\"\\nüìå 5 Random Samples After Normalization:\")\n",
        "    print(df_normalized_df.sample(n=5, random_state=42))\n",
        "\n",
        "    # üìå Clusterizar os dados com o MiniSom treinado\n",
        "    clusters = [som.winner(sample) for sample in df_normalized]\n",
        "    cluster_labels = [x[0] * som_y + x[1] for x in clusters]\n",
        "    df[\"Cluster\"] = cluster_labels\n",
        "\n",
        "    print(\"\\nüìå 5 Random Samples After Clustering:\")\n",
        "    print(df.sample(n=5, random_state=42))\n",
        "\n",
        "    # üìå Fazer previs√µes usando o modelo correspondente a cada cluster\n",
        "    predicted_conductance = []\n",
        "    for i, sample in enumerate(df_normalized):\n",
        "        cluster = cluster_labels[i]\n",
        "        model = models.get(cluster)\n",
        "\n",
        "        if model is None:\n",
        "            predicted_conductance.append(None)\n",
        "        else:\n",
        "            # üìå Fazer a previs√£o com o modelo GBR correspondente ao cluster\n",
        "            pred_norm = model.predict(sample.reshape(1, -1))\n",
        "\n",
        "            # üìå Desnormalizar a previs√£o\n",
        "            pred_std = scaler_y_minmax.inverse_transform(pred_norm.reshape(-1, 1))\n",
        "            pred_real = scaler_y_standard.inverse_transform(pred_std)\n",
        "\n",
        "            predicted_conductance.append(pred_real[0][0])\n",
        "\n",
        "            if i < 5:  # Exibir apenas 5 previs√µes para n√£o poluir o console\n",
        "                print(f\"\\nüìå Sample {i+1}: Cluster {cluster}, GBR Model {cluster} utilizado.\")\n",
        "                print(f\"   Entrada para GBR: {sample}\")\n",
        "                print(f\"   Predi√ß√£o normalizada: {pred_norm[0]}\")\n",
        "                print(f\"   Predi√ß√£o desnormalizada: {pred_real[0][0]}\")\n",
        "\n",
        "    # üìå Adicionar previs√µes ao DataFrame\n",
        "    df[\"PredictedConductance\"] = predicted_conductance\n",
        "\n",
        "    print(\"\\nüìå DataFrame Final com Previs√µes:\")\n",
        "    print(df.head(10))  # Exibir as 10 primeiras linhas com previs√µes\n",
        "\n",
        "    return df  # Retorna o DataFrame final para inspe√ß√£o\n",
        "\n",
        "# üìå Perguntar ao usu√°rio qual √¢ngulo deseja usar\n",
        "while True:\n",
        "    try:\n",
        "        new_angle = float(input(\"\\nüìå Digite o √¢ngulo para previs√£o: \"))\n",
        "        break\n",
        "    except ValueError:\n",
        "        print(\"‚ùå Entrada inv√°lida! Digite um n√∫mero v√°lido para o √¢ngulo.\")\n",
        "\n",
        "# üìå Executar previs√£o sem salvar resultados\n",
        "final_df = predict_conductance_for_angle(new_angle)\n",
        "\n",
        "print(\"\\n‚úÖ Processo conclu√≠do! O DataFrame com previs√µes foi gerado.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CobqvywcdNZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "5b639fe0-8e18-4c3c-974e-48c127089afc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelos e escaladores carregados!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf619d4a9288>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mnew_angle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìå Digite o √¢ngulo para previs√£o: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Saving the results"
      ],
      "metadata": {
        "id": "i2456q_54O2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving results files to calculate resistance\n",
        "\n",
        "*   Normalize the input data (energy, angle, contact pairs) using the pre-trained scalers.\n",
        "\n",
        "*   Identify the cluster of the input using the MiniSom model.\n",
        "\n",
        "*   Select the appropriate GBR model for the identified cluster.\n",
        "\n",
        "*   Predict the conductance using the chosen GBR model.\n",
        "\n",
        "*   Denormalize the predicted conductance to return a final real-world value.\n"
      ],
      "metadata": {
        "id": "8hJ4T7yrdFOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import sys\n",
        "\n",
        "# üìå Definir o mapeamento original dos contatos\n",
        "arrival_mapping = {'1u': 1, '2u': 2, '3u': 3, '4u': 4, '1d': 5, '2d': 6, '3d': 7, '4d': 8}\n",
        "exit_mapping = arrival_mapping.copy()\n",
        "\n",
        "# üìå Criar diret√≥rio se n√£o existir\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# üìå Criar mapeamento reverso dos contatos (index -> nome real)\n",
        "reverse_mapping = {v: k for k, v in arrival_mapping.items()}\n",
        "\n",
        "# üìå Iterar sobre cada par ArrivalPair/ExitPair e salvar arquivos individuais\n",
        "saved_files = []\n",
        "for (arrival, exit_), group_df in final_df.groupby([\"ArrivalPair\", \"ExitPair\"]):\n",
        "    # üìå Converter √≠ndice de volta para o nome real do contato\n",
        "    arrival_name = reverse_mapping[arrival]\n",
        "    exit_name = reverse_mapping[exit_]\n",
        "\n",
        "    # üìå Converter √¢ngulo para formato \"3p0\" (substituir \".\" por \"p\")\n",
        "    angle_str = str(new_angle).replace(\".\", \"p\")\n",
        "\n",
        "    # üìå Formatar nome do arquivo usando os nomes reais dos contatos\n",
        "    filename = f\"G{arrival_name}{exit_name}_AA50x50_{angle_str}_0T_th.dat\"\n",
        "    output_file = os.path.join(save_directory, filename)\n",
        "\n",
        "    # üìå Salvar DataFrame do grupo no arquivo correspondente\n",
        "    group_df.to_csv(output_file, sep=\" \", index=False, header=True)\n",
        "\n",
        "    print(f\"‚úÖ Arquivo salvo: {output_file}\")\n",
        "    saved_files.append(output_file)\n",
        "\n",
        "# üìå Se estiver no Google Colab, compactar os arquivos e baixar\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"\\nüì¶ Criando um arquivo ZIP para download...\")\n",
        "\n",
        "    zip_filename = \"/content/predicted_conductances.zip\"\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for file in saved_files:\n",
        "            zipf.write(file, os.path.basename(file))  # Adiciona ao ZIP sem os diret√≥rios\n",
        "\n",
        "    print(f\"\\nüì¶ Arquivo ZIP gerado: {zip_filename}\")\n",
        "\n",
        "    # üìå Baixar automaticamente o arquivo ZIP no Colab\n",
        "    from google.colab import files\n",
        "    files.download(zip_filename)\n",
        "    print(\"\\nüì• O download do arquivo compactado foi iniciado!\")\n",
        "\n",
        "print(\"\\n‚úÖ Processo conclu√≠do! Todos os arquivos foram gerados e salvos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-W7db9ZQeqvy",
        "outputId": "a6d4b03d-9d28-4f29-c90c-dbc5137f8aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u3d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1u4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u3d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2u4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u3d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3u4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u3d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4u4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d3d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G1d4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d3d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G2d4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G3d4d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d1u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d2u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d3u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d4u_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d1d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d2d_AA50x50_3p0_0T_th.dat\n",
            "‚úÖ Arquivo salvo: C:\\Users\\PICHAU\\Desktop\\Condut√¢ncias preditas/G4d3d_AA50x50_3p0_0T_th.dat\n",
            "\n",
            "üì¶ Criando um arquivo ZIP para download...\n",
            "\n",
            "üì¶ Arquivo ZIP gerado: /content/predicted_conductances.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_115a08dc-a643-4a81-bbc4-4f421b2667b4\", \"predicted_conductances.zip\", 567449)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì• O download do arquivo compactado foi iniciado!\n",
            "\n",
            "‚úÖ Processo conclu√≠do! Todos os arquivos foram gerados e salvos.\n"
          ]
        }
      ]
    }
  ]
}